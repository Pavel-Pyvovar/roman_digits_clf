{% extends "layout.html" %}
{% block content %}
<h1 id="roman-digits-classification">Roman digits classification</h1>
<h2 id="introduction">Introduction</h2>
<ol style="list-style-type: decimal">
<li><a href="#config">Config</a></li>
<li><a href="#data-structure">Data structure</a></li>
<li><a href="#data-description-and-cleaning-process">Data description and cleaning process</a></li>
<li><a href="#data-augmentation-and-splitting">Data augmentation and splitting</a></li>
<li><a href="#model-structure">Model structure</a></li>
<li><a href="#instructions-to-run-the-model">Instructions to run the model</a></li>
<li><a href="#data-preparation">Data preparation</a></li>
<li><a href="#running-model">Running model</a></li>
<li><a href="#results">Results</a></li>
<li><a href="#authors">Authors</a></li>
</ol>
<h2 id="config">Config</h2>
<p><strong><em>Config files must be located at <code>configs</code> folder.</em></strong></p>
<p>Parameters specific for data generation:</p>
<ul>
<li><code>seed</code> - seed for random shuffling.</li>
<li><code>image_size</code> - size of the side for resulting image.</li>
<li><code>number_to_have</code> - number of images to have in <code>data_clean/_class_</code> directory.</li>
</ul>
<p>Parameters specific for model:</p>
<ul>
<li><code>exp_name</code> - defines the model name and paths to write summaries and weights in.</li>
<li><code>learning rate</code> - learning rate to train model with.</li>
<li><code>use_dropout_block</code> - if to use dropout between convolutions.</li>
<li><code>use_dropout_dense</code> - if to use dropout after dense layer.</li>
<li><code>dropout_rate_block</code> - dropout rate to use between convolutions.</li>
<li><code>dropout_rate_dense</code> - dropout rate to use after dense layer.</li>
<li><code>write_histograms</code> - if to write histograms for distribution of activations for each layer.</li>
</ul>
<h2 id="data-structure">Data structure</h2>
<p><code>data</code> folder contains original <em>'dirty'</em> data of Roman images, split by classes. The number of images in a single class folder can be any from 0 to Infinity.<br />For example, folder <code>data/1</code> contains all images marked as class <code>1</code>.</p>
<p><code>data_clean</code> folder contains resized, grayscaled and augmented images, split by classes. The number of images in a single class folder must be set in the config file.<br />For example, the folder <code>data_clean/1</code> contains resized, grayscaled and augmented images, marked as class <code>1</code>.</p>
<p><code>data_splitted</code> folder contains data, split into train and test datasets. The number of single class in train dataset must be set in the config file.<br />For example, <code>data_clean/train/1</code> contains train images, marked as class <code>1</code>.</p>
<h2 id="data-description-and-cleaning-process">Data description and cleaning process</h2>
<p>It was decided to create about 120 images for each class (roman numbers from 1 to 8) and augment that data to get a more versatile dataset so that neural network could be more robust to different variations of data. To achieve a goal of 120 images per class, every team member wrote his variations of roman digits with his/her unique handwriting multiple times.</p>
<p>The process of data cleaning includes resizing images, grayscaling them and saving to folder <code>data_clean</code>.</p>
<h2 id="data-augmentation-and-splitting">Data augmentation and splitting</h2>
<p>Data augmentation contains applying multiple transformations to data, such as:</p>
<ul>
<li>Cropping;</li>
<li>Padding;</li>
<li>Blurring;</li>
<li>Different affine transformations</li>
</ul>
<p>Data will be generated into the folder <code>data_clean/_class_</code> near existing images.</p>
<p>Splitting data contains the process of reading filenames of images and resaving them into folder <code>data_splitted/(train or test)/_class_</code>.</p>
<h2 id="model-structure">Model structure</h2>
<p>We had a task of image classification so that it was decided to use a convolutional network with some tricks and whistles.<br />The main graph of the model is shown below.</p>
<p><details> <summary><b>Graph</b></summary> <img src="figures/graph.png" width="100%"/> </details></p>
<p>Our model consists of 5 blocks, where <code>block_1</code> - <code>block_4</code> are convolution blocks and <code>dense</code> block containing only dense layers. Architectures of each block are separately described below.</p>
<h3 id="blocks-1-3">Blocks 1-3</h3>
<p>Notice that convolution blocks 1-3 have the same next architecture and channel growth in them is caused by stacking pooling layers:</p>
<pre><code>Conv2D -&gt; BatchNormalization -&gt; ReLU -&gt; Dropout (if necessary) -&gt;
-&gt; Conv2D -&gt; BatchNormalization -&gt; ReLU -&gt; concatenated MaxPooling and Average Pooling</code></pre>
<p>Convolution kernels have sizes of 3x3 and stride of 1x1.<br />Max- and Average-pooling layers have sizes and strides of 2x2 each.</p>
<p><details> <summary><b>Block structure</b></summary> <img src="figures/bl_123.png" width="100%"/> </details></p>
<h3 id="block-4">Block 4</h3>
<p>In 4th convolution block we do not use stacking of pooling layers, so that number of channels here grows naturally:</p>
<pre><code>Conv2D -&gt; BatchNormalization -&gt; ReLU -&gt; Dropout (if necessary) -&gt;
-&gt; Conv2D -&gt; BatchNormalization -&gt; ReLU -&gt; MaxPooling</code></pre>
<p>Convolution kernels have sizes of 3x3. The strides of the first one is 1x1 and the second one is 2x2.<br />Max-pooling layer has size and stride of 2x2.</p>
<p><details> <summary><b>Block structure</b></summary> <img src="figures/bl_4.png" width="100%"/> </details></p>
<h3 id="dense-block">Dense block</h3>
<p>Dense block consists of 2 hidden dense layers with batch norm and leaky relu between them:</p>
<pre><code>Dense -&gt; BatchNormalization -&gt; LeakyReLU -&gt; Dropout (if necessary) -&gt;
-&gt; Dense -&gt; Softmax</code></pre>
<p><details> <summary><b>Block structure</b></summary> <img src="figures/bl_dense.png" width="100%"/> </details></p>
<p>Calculated input and output sizes of each layer are under the spoiler. <details> <summary><b>Input and output sizes:</b></summary></p>
<ul>
<li>Block 1:</li>
<li>Input size: (?, 128, 128, 3)</li>
<li>Output size: (?, 62, 62, 32)</li>
<li>Block 2:</li>
<li>Input size: (?, 62, 62, 32)</li>
<li>Output size: (?, 29, 29, 64)</li>
<li>Block 3:</li>
<li>Input size: (?, 29, 29, 64)</li>
<li>Output size: (?, 12, 12, 128)</li>
<li>Block 4:</li>
<li>Input size: (?, 12, 12, 128)</li>
<li>Output size: (?, 4, 4, 256)</li>
<li>Reshape:</li>
<li>Input size: (?, 4, 4, 256)</li>
<li>Output size: (?, 1024)</li>
<li>Dense:</li>
<li>Input size: (?, 1024)</li>
<li>Output size: (?, 8)</li>
</ul>
<p></details></p>
<h2 id="instructions-to-run-the-model">Instructions to run the model</h2>
<p>Our project is based on some libraries you might not have. To ensure everything is installed and install missed packages run next commands.</p>
<pre class="sh"><code>cd path/to/project/roman_clf
pip install -r requirements.txt</code></pre>
<h3 id="data-preparation">Data preparation</h3>
<p>This script will do all the stuff related to data preparation fast and clean. To run it follow instructions below.</p>
<pre class="sh"><code>cd path/to/project/roman_clf
python prepare_data.py -c ../configs/roman.json</code></pre>
<p>It is easy, isn't it? :)</p>
<h3 id="running-model">Running model</h3>
<p>To run the model follow instructions below.</p>
<p>Open and run jupyter notebook <a href="https://github.com/VVRud/roman_clf/blob/master/src/Best_Model.ipynb"><code>roman_clf/src/Best_Model.ipynb</code></a></p>
<p>All necessary libraries will be imported and configs will be set up automatically. All you need to do is just click <code>run</code> for all cells.</p>
<p>Model class is formatted into the notebook, as an example, but can be moved to a different file if it would be necessary.</p>
<p>To run the model you will need a lot of computation power. If you don't have it, try using a batch size of 1, it should help.</p>
<h2 id="results">Results</h2>
<p>After being trained for 1050 epochs, our CNN showed next results:</p>
<p><code>Train loss:</code> 1.280041337</p>
<p><code>Train accuracy:</code> <strong>0.9940649271</strong></p>
<p><br/></p>
<p><code>Test loss:</code> 1.2813329697</p>
<p><code>Test accuracy:</code> <strong>0.9926757812</strong></p>
<h2 id="authors">Authors</h2>
<ul>
<li><a href="https://github.com/vvrud">Vladyslav Rudenko</a></li>
<li><a href="https://github.com/vivikar">Vladyslav Zalevskyi</a></li>
<li><a href="https://github.com/pavel-pyvovar">Pavlo Pyvovar</a></li>
<li><a href="https://github.com/datacat01">Olga Pashneva</a></li>
</ul>

{% endblock content %}